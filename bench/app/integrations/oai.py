from openai import OpenAI
from openai.types.chat import ChatCompletion

from app.llm.config import LLMConfig
from datetime import datetime
class OpenAIAPI:
    def __init__(self, config: LLMConfig):
        self.config = config
        self.client = OpenAI(api_key=config.OPENAI_API_KEY)
        self.seed = 1337
        self.model = ""
        
    def list(self):
        return {'models': [{"name": "gpt-3.5-turbo", "description": "GPT-3.5 Turbo"}, {"name": "gpt-4-turbo-preview", "description": "GPT-4 Turbo (Preview)"}]}
           
    
    def chat(self, message: str, model: str = 'gpt-3.5-turbo'):
        # models: gpt-3.5-turbo gpt-4-turbo-preview
        self.model = model
        print("Sending OpenAI request", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        chat_completion = self.client.chat.completions.create(
        max_tokens=self.config.max_tokens,
        seed=self.seed,
        temperature=self.config.temperature,
        # top_p=1,
        # frequency_penalty=0,
        # presence_penalty=0
    
        messages=[
            {
                "role": "system",
                "content": self.config.system_message
            },
            {
                "role": "user",
                "content": message,
            }
        ],
        model=model,
       )
        response_content = chat_completion.choices[0].message.content
        return chat_completion
    
    def parse(self, message: str, response: ChatCompletion):
        try:
            answer = response.choices[0].message.content
            created_at = response.created
            system_fingerprint = response.system_fingerprint
            model = self.model
            seed = self.seed
            return {
                "message": message,
                "answer": answer,
                "model": model,
                "created_at": created_at,
                "system_fingerprint": system_fingerprint,
                "seed": seed,
                "system_msg": self.config.system_message,
                "temperature": self.config.temperature,
            }
        except KeyError:
            print(response)
            exit(1)
            
    def print_response(self, response: ChatCompletion):
        print(response.choices[0].message.content)