import requests
from app.llm.config import LLMConfig

ENDPOINT = "http://localhost:11434/api"
LIST_ENDPOINT = f"{ENDPOINT}/tags"
CHAT_ENDPOINT = f"{ENDPOINT}/chat"

class OllamaApi:
    def __init__(self, config: LLMConfig):
        self.config = config
        
    
    def list(self):
        response = requests.get(LIST_ENDPOINT)
        return response.json()

    
    def chat(self, message: str, model: str):
        options = {
                    "seed": 1337,
                    # "num_gpu": 1,
                    # "main_gpu": 0,
                    # "f16_kv": True,
                    # "num_thread": 6,
                    # "low_vram": False,
                    # "use_mmap": True,
                    # "use_mlock": False,
                    # "vocab_only": False,
                    # "embedding_only": False,
                    "temperature": self.config.temperature,
                    
                }
        if self.config.max_tokens:
            options.update({"num_predict": self.config.max_tokens})
            
        if self.config.more_options:
            options.update(self.config.more_options)
            
        response = requests.post(
            CHAT_ENDPOINT,
            json={
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": message,
                    }
                ],
                "options": options,
                "stream": False,
            },
        )
        return response.json()

    
    def parse(self, message: str, response: str):
        try:
            answer = response["message"]["content"]
            created_at = response.get("created_at")
            total_duration = response.get("total_duration")
            load_duration = response.get("load_duration")
            prompt_eval_count = response.get("prompt_eval_count", "")
            prompt_eval_duration = response.get("prompt_eval_duration", "")
            eval_count = response.get("eval_count")
            eval_duration = response.get("eval_duration")
            model = response.get("model")
            temperature = self.config.temperature
            return {
                "message": message,
                "answer": answer,
                "model": model,
                "created_at": created_at,
                "total_duration": total_duration,
                "load_duration": load_duration,
                "prompt_eval_count": prompt_eval_count,
                "prompt_eval_duration": prompt_eval_duration,
                "eval_count": eval_count,
                "eval_duration": eval_duration,
                "temperature": temperature,
            }
        except KeyError:
            print(response)
            exit(1)
            
    def print_response(self, response: dict):
        print(response["message"]["content"])